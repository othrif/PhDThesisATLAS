Some notable discoveries in particles physics are those of the 
$W$ and $Z$ bosons \cite{Arnison:1984qu,Bagnaia:1983zx}, the top quark  
\cite{PhysRevLett.74.2626,Abachi:1995iq}, and the Higgs boson \cite{atlas_higgs, cms_higgs}.
The path towards the discovery of these particles was guided by 
theoretical insight which gave great confidence that these particles 
should exist. 
For instance, the features of the $W$ and $Z$ bosons, such as their mass 
and production rates, were known in advance. 
Their signals stood out from the backgrounds without ambiguity.
The top quark discovery was harder, but its production and decay 
properties were predicted.
For the Higgs, there was reasonable evidence for its existence.
The production and decay of the Higgs were all known as a function of 
mass, the only missing parameter in the theory. 
In fact, these properties were also known for alternative models 
to the SM implementation of the Higgs mechanism.

Today, we do not have such theoretical guidance, and thus our task 
is notably more difficult.
The strategy followed at the LHC is to aim at establishing 
significant deviations from the SM by carefully examining 
if the observed signal is not consistent with the standard model expectation.
The second step is to understand what this deviation corresponds to 
in the vast space of possible beyond the SM scenarios.

There are three possible scenarios to establish a deviation from  the 
SM expectation: invariant mass peaks, 
anomalous shapes of kinematic distributions, and excess in counting 
experiments.
By examining invariant mass distributions of dilepton, diphoton, or 
dijet final states, a peak that stands out from the background 
continuum that is not predicted by the SM is the most clear indication 
of a new physics signal.
The benefit of this type of signal is that the background can be directly 
taken from data by mere extrapolation of the sidebands of the invariant 
mass below and above the peak. As a result, the simulation will not 
be important in this scenario, which is desirable to avoid any 
mis-modelling or inaccuracies of the simulation.
The second strategy aims at establishing a clear difference in the shape 
of a given kinematic variable between the 
observed data from the expected SM background. 
Distributions, like the missing transverse momentum or the effective 
mass defined as the sum of all reconstructed objects 
and missing transverse momentum in the event, 
are chosen to be sensitive to new physics scenarios.
This approach relies 
heavily on a  precise knowledge of the SM background shapes.
For this reason, special care must be taken to validate the accuracy 
of the SM modeling. 
The claim that a new signal exists is far too important to only rely 
on a direct comparison with Monte Carlo simulation. For this reason, 
a combination of data-driven and correction techniques are employed. 
Often times, data is used internally to correct 
the shape and normalization of the SM backgrounds and to validate the estimate 
before extrapolating to the search region represented by a kinematic 
distribution of a given variable.
The last strategy aims at defining some selection criteria expected to 
increase the probability for observing a new signal, then counting the 
number of observed events passing the cuts and comparing it to 
the expected background.
In a sense, this strategy is similar to the shape discrepancy case 
except that an integral over the  full sample 
passing the cuts is taken since the statistics is typically low.
As a consequence, counting experiments require an even more careful
assessment of the background to achieve the most robust 
understanding of the expected prediction.

The work described in this dissertation follows the last strategy 
of designing several counting experiments. The essential part of the 
work is in establishing a reliable background estimate in these 
experiments to access the compatibility of the observed data with the 
predicted background.
